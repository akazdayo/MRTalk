import { useMeshStore } from "./XRMeshes";
import { useFrame, useThree } from "@react-three/fiber";
import {
  useXR,
  useXRInputSourceEvent,
  useXRInputSourceState,
} from "@react-three/xr";
import { useReactMediaRecorder } from "react-media-recorder";
import { Character } from "@prisma/client";
import TextBox from "./TextBox";
import { MovementManager } from "~/lib/xr/vrm/MovementManager";
import { AnimationManager } from "~/lib/xr/vrm/AnimationManager";
import { VRMLoader } from "~/lib/xr/vrm/VRMLoader";
import { useEffect, useRef, useState } from "react";
import { GLTF } from "three/examples/jsm/loaders/GLTFLoader.js";
import { Chat } from "~/lib/llm/Chat";
import {
  AgentManager,
  NavMeshManager,
  RecastNavMeshFactory,
} from "~/lib/xr/navigation/NavigationManager";
import { init } from "@recast-navigation/core";
import { VRM as VRMType } from "@pixiv/three-vrm";
import { Buffer } from "buffer";

//TODO:„É™„Éï„Ç°„ÇØ„Çø„Åô„Çã
export default function VRM({ character }: { character: Character }) {
  const [gltf, setGltf] = useState<GLTF | null>(null);
  const [text, setText] = useState<string>("Ë©±„Åó„Åã„Åë„Å¶„Åø„Åæ„Åó„Çá„ÅÜÔºÅ");

  const xr = useXR();

  const timeDomainData = new Float32Array(2048);

  const isCompleteSetup = useRef<boolean>(false);

  const chat = useRef(new Chat(character.id));
  const movementManager = useRef<MovementManager | null>(null);
  const animationManager = useRef<AnimationManager | null>(null);

  const audioCtx = useRef<AudioContext | null>(null);
  const analyser = useRef<AnalyserNode | null>(null);

  const { gl } = useThree();
  const meshes = useMeshStore((state) => state.meshes);
  const getMeshByLabel = useMeshStore((state) => state.getMeshByLabel);

  const { startRecording, stopRecording } = useReactMediaRecorder({
    audio: true,
    onStop(blobUrl, blob) {
      onResult(blob);
    },
  });

  const onResult = async (blob: Blob) => {
    movementManager.current?.toggleThinking();

    try {
      const res = await chat.current.voiceChat(blob);
      // res will be of type Res from z.infer<typeof ResponseSchema>
      // which now includes game_ai_choice and game_result thanks to prior schema update.

      let displayText = res.content;
      // Helper to translate choices/results if needed, or use raw values
      const translateAIChoice = (choice: string | undefined | null) => {
        if (!choice) return "";
        // Simple mapping, can be expanded
        const map: { [key: string]: string } = {
          rock: "„Ç∞„Éº‚úä",
          paper: "„Éë„ÉºüñêÔ∏è",
          scissors: "„ÉÅ„Éß„Ç≠‚úåÔ∏è",
        };
        return map[choice] || choice;
      };

      const translateGameResult = (result: string | undefined | null) => {
        if (!result) return "";
        const map: { [key: string]: string } = {
          win: "Âãù„Å°üéâ",
          lose: "Ë≤†„Åëüò¢",
          draw: "Âºï„ÅçÂàÜ„Åëü§ù",
        };
        return map[result] || result;
      };

      if (res.game_ai_choice) {
        displayText += `\nÁõ∏Êâã„ÅÆÊâã: ${translateAIChoice(
          res.game_ai_choice
        )}`;
      }
      if (res.game_result) {
        displayText += `\nÁµêÊûú: „ÅÇ„Å™„Åü„ÅÆ${translateGameResult(res.game_result)}`;
      }
      setText(displayText);

      const sound = "data:audio/wav;base64," + res.voice;
      const audio = new Audio();
      audio.src = sound;

      const buffer = Buffer.from(res.voice, "base64");

      if (audioCtx.current) {
        audioCtx.current.decodeAudioData(
          buffer.buffer.slice(
            buffer.byteOffset,
            buffer.byteOffset + buffer.byteLength
          ),
          (audioBuffer) => {
            if (analyser.current && audioCtx.current) {
              const bufferSource = audioCtx.current.createBufferSource();
              bufferSource.buffer = audioBuffer;
              bufferSource.connect(audioCtx.current.destination);
              bufferSource.connect(analyser.current);
              bufferSource.start();
            }
          }
        );
      }

      if (movementManager.current && res.event) {
        movementManager.current.setEvent(res.event);
      }

      const arr = Object.entries(res.emotion);
      arr.sort((a, b) => b[1] - a[1]);

      movementManager.current?.toggleThinking();

      animationManager.current?.setEmotion(arr[0][0]);
      movementManager.current?.toggleTalking();

      setTimeout(() => {
        movementManager.current?.toggleTalking();
        animationManager.current?.resetEmotion();
      }, 10000);
    } catch (e: unknown) {
      movementManager.current?.toggleThinking();
      animationManager.current?.resetEmotion();

      if (e instanceof Error) {
        setText(e.message);
      }
    }
  };

  const controller = useXRInputSourceState("hand", "left");

  useXRInputSourceEvent(
    controller?.inputSource,
    "selectstart",
    () => {
      if (!movementManager.current?.isThinking) {
        setText("Èå≤Èü≥‰∏≠...");
        startRecording();
      }
    },
    [controller]
  );

  useXRInputSourceEvent(
    controller?.inputSource,
    "selectend",
    () => {
      if (!movementManager.current?.isThinking) {
        setTimeout(() => {
          setText("ËÄÉ„Åà‰∏≠...");
          stopRecording();
        }, 500);
      }
    },
    [controller]
  );

  const getPlayerPosition = () => {
    return gl.xr.getCamera().position;
  };

  const onSessionStart = async () => {
    try {
      await init();
      const loader = new VRMLoader();

      const { gltf } = await loader.load(character.modelUrl);
      setGltf(gltf);

      const animation = new AnimationManager(gltf);
      await animation.load({
        idle: { path: "/anim/vrma/idle.vrma", isAdditive: false },
        walk: { path: "/anim/vrma/walk.vrma", isAdditive: false },
        sit: { path: "/anim/vrma/sit_anim.vrma", isAdditive: false },
        thinking: { path: "/anim/vrma/thinking.vrma", isAdditive: true },
        looking: { path: "/anim/vrma/looking.vrma", isAdditive: false },
        stretch: { path: "/anim/vrma/stretch.vrma", isAdditive: false },
      });

      animationManager.current = animation;
    } catch (e) {
      alert("„É¢„Éá„É´„ÅÆ„É≠„Éº„Éâ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ");
    }

    try {
      const ctx = new window.AudioContext();
      const a = ctx.createAnalyser();

      audioCtx.current = ctx;
      analyser.current = a;
      window.Buffer = Buffer;
    } catch (e) {
      alert("Audio Analyser„ÅÆ„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ");
    }
  };

  const setupNavMesh = () => {
    try {
      if (
        isCompleteSetup.current ||
        !gltf ||
        !animationManager.current ||
        !xr.session
      )
        return;

      //NavMesh„Çí„Éô„Ç§„ÇØ
      const navigation = new NavMeshManager(new RecastNavMeshFactory());
      navigation.bake(Array.from(meshes.values()));

      //NavMesh„ÇíÂèñÂæó
      const navMesh = navigation.getNavMesh();
      if (!navMesh) return;

      const agent = new AgentManager(navMesh);

      const movement = new MovementManager(
        gltf,
        animationManager.current,
        agent,
        getMeshByLabel,
        getPlayerPosition,
        xr.session
      );

      movementManager.current = movement;

      isCompleteSetup.current = true;
    } catch (e) {
      alert("ÈÉ®Â±ã„ÅÆËß£Êûê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ");
    }
  };

  gl.xr.addEventListener("sessionstart", onSessionStart);

  useEffect(() => {
    setupNavMesh();
  }, [meshes]);

  useFrame(() => {
    if (animationManager.current) {
      animationManager.current.update();
    }

    if (movementManager.current) {
      movementManager.current.update();
    }

    //„É™„ÉÉ„Éó„Ç∑„É≥„ÇØ(‰ªÆ)
    if (analyser.current && gltf) {
      analyser.current.getFloatTimeDomainData(timeDomainData);

      let volume = 0.0;
      for (let i = 0; i < 2048; i++) {
        volume = Math.max(volume, Math.abs(timeDomainData[i]));
      }

      volume = 1 / (1 + Math.exp(-45 * volume + 5));
      if (volume < 0.1) volume = 0;

      const vrm: VRMType = gltf.userData.vrm;

      vrm.expressionManager?.setValue("aa", volume);
    }
  });

  return (
    <>
      {gltf ? (
        <>
          <group>
            <primitive object={gltf.scene} scale={0.85} />
            <directionalLight position={[0, 10, 0]} />
          </group>

          <TextBox text={text} camera={gl.xr.getCamera()} gltf={gltf} />
        </>
      ) : null}
    </>
  );
}
