{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "MTiwR5PFAakG",
        "txxiQI_ij_zI",
        "SmafgXWBjNRQ"
      ],
      "authorship_tag": "ABX9TyOKjSbrlWjgR1PnxGgp1UN2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 環境構築"
      ],
      "metadata": {
        "id": "MTiwR5PFAakG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF7UvMRF-5LU",
        "outputId": "986113ef-42b3-45b9-d3c0-d589eaad36d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MRTalk-GPT-SoVITS'...\n",
            "remote: Enumerating objects: 4688, done.\u001b[K\n",
            "remote: Total 4688 (delta 0), reused 0 (delta 0), pack-reused 4688 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4688/4688), 13.16 MiB | 3.63 MiB/s, done.\n",
            "Resolving deltas: 100% (2703/2703), done.\n",
            "Updating files: 100% (300/300), done.\n",
            "/content/MRTalk-GPT-SoVITS\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/marukun712/MRTalk-GPT-SoVITS.git\n",
        "%cd MRTalk-GPT-SoVITS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -q -r requirements.txt\n",
        "!uv pip install -q ffmpeg-python pyopenjtalk pyngrok"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jKbbVuq_BQ6z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat <<EOF >  /content/MRTalk-GPT-SoVITS/GPT_SoVITS/configs/tts_infer.yaml\n",
        "custom:\n",
        "  bert_base_path: GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
        "  cnhuhbert_base_path: GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
        "  device: cuda\n",
        "  is_half: true\n",
        "  t2s_weights_path: GPT_SoVITS/pretrained_models/s1v3.ckpt\n",
        "  version: v4\n",
        "  vits_weights_path: GPT_SoVITS/pretrained_models/gsv-v4-pretrained/s2Gv4.pth\n",
        "v1:\n",
        "  bert_base_path: GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
        "  cnhuhbert_base_path: GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
        "  device: cpu\n",
        "  is_half: false\n",
        "  t2s_weights_path: GPT_SoVITS/pretrained_models/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt\n",
        "  version: v1\n",
        "  vits_weights_path: GPT_SoVITS/pretrained_models/s2G488k.pth\n",
        "v2:\n",
        "  bert_base_path: GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
        "  cnhuhbert_base_path: GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
        "  device: cpu\n",
        "  is_half: false\n",
        "  t2s_weights_path: GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s1bert25hz-5kh-longer-epoch=12-step=369668.ckpt\n",
        "  version: v2\n",
        "  vits_weights_path: GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth\n",
        "v3:\n",
        "  bert_base_path: GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
        "  cnhuhbert_base_path: GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
        "  device: cpu\n",
        "  is_half: false\n",
        "  t2s_weights_path: GPT_SoVITS/pretrained_models/s1v3.ckpt\n",
        "  version: v3\n",
        "  vits_weights_path: GPT_SoVITS/pretrained_models/s2Gv3.pth\n",
        "v4:\n",
        "  bert_base_path: GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
        "  cnhuhbert_base_path: GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
        "  device: cpu\n",
        "  is_half: false\n",
        "  t2s_weights_path: GPT_SoVITS/pretrained_models/s1v3.ckpt\n",
        "  version: v4\n",
        "  vits_weights_path: GPT_SoVITS/pretrained_models/gsv-v4-pretrained/s2Gv4.pth\n",
        "EOF"
      ],
      "metadata": {
        "id": "I4wJnUsqC36h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm ./GPT_SoVITS/pretrained_models/.gitignore\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS ./GPT_SoVITS/pretrained_models/"
      ],
      "metadata": {
        "id": "pO4uylfkElV7",
        "outputId": "4e1d78ca-4eb3-462a-8764-6eb52468af0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './GPT_SoVITS/pretrained_models'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 53 (delta 9), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (53/53), 111.70 KiB | 2.54 MiB/s, done.\n",
            "Filtering content: 100% (13/13), 3.49 GiB | 29.96 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch Server\n",
        "Google Colabのシークレット環境変数(左側のタブにあります)にNGROK_TOKEN, NGROK_DOMAIN, DATABASE_URLを追加する必要があります。  \n",
        "https://ngrok.com/"
      ],
      "metadata": {
        "id": "txxiQI_ij_zI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "\n",
        "TOKEN = userdata.get(\"NGROK_TOKEN\")\n",
        "DOMAIN = userdata.get(\"NGROK_DOMAIN\")\n",
        "DATABASE_URL = userdata.get(\"DATABASE_URL\")\n",
        "%env DATABASE_URL=$DATABASE_URL\n",
        "\n",
        "ngrok.set_auth_token(TOKEN)\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(9880, domain=DOMAIN)\n",
        "print('PUBLIC_URL:',ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "id": "XMI_yJmqhf-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5a72db-b91a-43ee-aadf-d1364110439a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PUBLIC_URL: https://eagle-cosmic-perfectly.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python api_v2.py -a 127.0.0.1 -p 9880 -c GPT_SoVITS/configs/tts_infer.yaml > server.log 2>&1 &"
      ],
      "metadata": {
        "id": "flolguAjJQb8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo\n",
        "Colab上から動かせるようにしました。  \n",
        "text: 読み上げ文章  \n",
        "ref_audio_path: 学習/参照する声のパス(currentpathはMRTalk-GPT-SoVITSです)  \n",
        "prompt_text: ref_audioが読み上げている文章  \n"
      ],
      "metadata": {
        "id": "SmafgXWBjNRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ref_audio.wavにサンプル音声を入れてください。\n",
        "import requests\n",
        "\n",
        "PATH = \"http://127.0.0.1:9880\"\n",
        "\n",
        "def tts_get():\n",
        "    # GETリクエストのパラメータを設定\n",
        "    params = {\n",
        "        'text': 'てきすと',\n",
        "        'text_lang': 'ja',\n",
        "        'ref_audio_path': 'ref_audio.wav',\n",
        "        'prompt_text': '入力プロンプト',\n",
        "        'prompt_lang': 'ja',\n",
        "        'media_type': 'wav',\n",
        "        'streaming_mode': 'false'\n",
        "    }\n",
        "\n",
        "    # GETリクエストを送信\n",
        "    response = requests.get(PATH + '/tts', params=params)\n",
        "\n",
        "    # レスポンスの処理\n",
        "    if response.status_code == 200:\n",
        "        # 音声データをファイルに保存\n",
        "        with open('output_get.wav', 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print('音声ファイルをoutput_get.wavに保存しました。')\n",
        "    else:\n",
        "        print(f\"エラー {response.status_code}: {response.text}\")\n",
        "\n",
        "tts_get()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGQwrOQl9nxO",
        "outputId": "ae499398-af19-4059-f036-45dff969ca82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "音声ファイルをoutput_get.wavに保存しました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat server.log"
      ],
      "metadata": {
        "id": "7wkj5GwK80Gz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}